import statsmodels.api as sm
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.outliers_influence import variance_inflation_factor

# =======================================================
# í°íŠ¸ ì„¤ì • (í•œê¸€ ê¹¨ì§ ë°©ì§€)
# =======================================================
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€
# =======================================================

# --- 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ ---
DATA_FILE = "maple_analysis_data_N450_final.csv" # ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ì˜ íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•¨

st.set_page_config(layout="wide")
st.title("ë©”ì´í”ŒìŠ¤í† ë¦¬ : ì§ì—…ë³„ ì„±ì¥ íš¨ìœ¨ ë¶„ì„")
st.markdown("---")

@st.cache_data
def load_data():
    try:
        df = pd.read_csv(DATA_FILE, encoding='utf-8-sig')
        return df
    except FileNotFoundError:
        st.error(f"'{DATA_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return None

df = load_data()

if df is not None:
    
    # --- A. ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ì§„ë‹¨ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ---
    required_cols = ['ì§ì—…ë¶„ë¥˜', 'ì „íˆ¬ë ¥', 'ì£¼ìŠ¤íƒ¯', 'ë³´ìŠ¤_ëª¬ìŠ¤í„°_ë°ë¯¸ì§€', 'í¬ë¦¬í‹°ì»¬_ë°ë¯¸ì§€', 'ë°©ì–´ìœ¨_ë¬´ì‹œ']    
    missing_cols = [col for col in required_cols if col not in df.columns]

    if missing_cols:
        st.error(f"âŒ ë°ì´í„°í”„ë ˆì„ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
        st.code(f"í˜„ì¬ ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}", language='python')
        st.stop()
    # --- ì§„ë‹¨ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ë ---

    # --- B. ë°ì´í„° í´ë¦¬ë‹ ë° íƒ€ì… ë³€í™˜ (Object dtype ì˜¤ë¥˜ í•´ê²°) ---
    
    # 1. ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ì •ì˜
    numeric_cols = ['ì „íˆ¬ë ¥', 'ì£¼ìŠ¤íƒ¯', 'ë³´ìŠ¤_ëª¬ìŠ¤í„°_ë°ë¯¸ì§€', 'í¬ë¦¬í‹°ì»¬_ë°ë¯¸ì§€', 'ë°©ì–´ìœ¨_ë¬´ì‹œ']

    for col in numeric_cols:
        if col in df.columns:
            # ìˆ¨ê²¨ì§„ ë¬¸ì/ì‰¼í‘œ/ê³µë°± ì œê±° ë° ê°•ì œ ë³€í™˜
            if df[col].dtype == 'object':
                 df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # 2. NaN (ê²°ì¸¡ì¹˜) ì²˜ë¦¬: íšŒê·€ ë¶„ì„ ì „ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì œê±°
    df.dropna(subset=numeric_cols + ['ì§ì—…ë¶„ë¥˜'], inplace=True) 
    
    # 3. ì‚¬ì´ë“œë°” ì •ë³´ í‘œì‹œ (í´ë¦¬ë‹ í›„ì˜ ìµœì¢… ìƒ˜í”Œ ìˆ˜)
    st.sidebar.header("ë¶„ì„ ì •ë³´")
    st.sidebar.metric("ì´ ìƒ˜í”Œ ìˆ˜", len(df))
    st.sidebar.metric("ë¶„ì„ ëŒ€ìƒ ì§ì—… ë¶„ë¥˜", df['ì§ì—…ë¶„ë¥˜'].nunique())

# --- 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° íšŒê·€ë¶„ì„ ---
    
    # ì¢…ì† ë³€ìˆ˜ (Y) ì„¤ì •
    Y = np.log1p(df['ì „íˆ¬ë ¥']) 
    Y.reset_index(drop=True, inplace=True) 
    
    # ì§ì—… ë¶„ë¥˜ ë”ë¯¸ ë³€ìˆ˜í™” (X_job)
    df['ì§ì—…ë¶„ë¥˜'] = df['ì§ì—…ë¶„ë¥˜'].astype(str)
    X_job = pd.get_dummies(df['ì§ì—…ë¶„ë¥˜'], drop_first=True, prefix='Job')
    
    # OLS ëª¨ë¸ì€ bool íƒ€ì…ì„ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ë¯€ë¡œ, 0ê³¼ 1ì˜ int íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    for col in X_job.columns:
        if X_job[col].dtype == 'bool':
            X_job[col] = X_job[col].astype(int)
    
    # í†µì œ ë³€ìˆ˜ (X_control) ì„¤ì •
    X_control = df[['ì£¼ìŠ¤íƒ¯', 'ë³´ìŠ¤_ëª¬ìŠ¤í„°_ë°ë¯¸ì§€', 'í¬ë¦¬í‹°ì»¬_ë°ë¯¸ì§€', 'ë°©ì–´ìœ¨_ë¬´ì‹œ']]

    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_control_scaled = scaler.fit_transform(X_control)
    X_control_scaled = pd.DataFrame(X_control_scaled, columns=X_control.columns)
    
    # ìµœì¢… ë…ë¦½ ë³€ìˆ˜ ë³‘í•©
    X = pd.concat([X_job.reset_index(drop=True), X_control_scaled.reset_index(drop=True)], axis=1)
    
    # ìƒìˆ˜í•­ ì¶”ê°€
    X = sm.add_constant(X, has_constant='add')
    
    # ëª¨ë¸ ì í•©
    try:
        model = sm.OLS(Y, X).fit()
    except Exception as e:
        st.error(f"âŒ íšŒê·€ ëª¨ë¸ ì í•© ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.warning("ë°ì´í„°ì˜ ëª¨ë“  ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì˜¤ë¥˜ê°€ ê³„ì†ë˜ë©´ ë°ì´í„°ë¥¼ ìƒ˜í”Œë§í•˜ê±°ë‚˜ ì¤„ì—¬ë³´ì‹­ì‹œì˜¤.")
        st.write("--- ìµœì¢… ë…ë¦½ ë³€ìˆ˜ Xì˜ DTYPES ---")
        st.dataframe(X.dtypes.to_frame(name='Dtype'))
        st.write("--- X ë³€ìˆ˜ ìƒìœ„ 5ê°œ í–‰ (í™•ì¸ìš©) ---")
        st.dataframe(X.head())
        st.stop()


# ëª©ì°¨ êµ¬ì„±
toc = {
    "ì˜ˆìƒ íš¨ìœ¨ ì‹œë®¬ë ˆì´ì…˜": [],
    "0. ë©”ì•Œëª»ì˜ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¶„ì„ê¸°": [
        "0.1. ì—°êµ¬ ë™ê¸°",
        "0.2. ë©”ì´í”ŒìŠ¤í† ë¦¬ë€?",
        "0.3. ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…"
    ],
    "1. ë¶„ì„ ë°©ë²•": [
        "1.1.-1.4. ë¶„ì„ ë°©ë²•"
    ],
    "2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ê²°ê³¼": [
        "2.1. ì§ì—… ë¶„ë¥˜ ìƒì„¸ ì •ë³´",
        "2.2. íšŒê·€ ë¶„ì„ ê²°ê³¼",
        "2.3. ê·¸ë˜í”„"
    ]
}

# ìƒìœ„ ì±•í„° ì„ íƒ
chapter = st.sidebar.selectbox("ğŸ“‚ ì±•í„° ì„ íƒ", list(toc.keys()))

# í•˜ìœ„ ì„¹ì…˜ ì„ íƒ
section = st.sidebar.radio("ğŸ“‘ ì„¹ì…˜ ì„ íƒ", toc[chapter])

# ë³¸ë¬¸ ì¶œë ¥

# ----------------------------------------------------
# --- â˜…â˜…â˜… ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€: ì˜ˆìƒ íš¨ìœ¨ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ â˜…â˜…â˜… ---
# ----------------------------------------------------

# 2. --- ì»¨í…Œì´ë„ˆ (ë²„íŠ¼ê³¼ ê²°ê³¼ë§Œ í¬í•¨) ---
if chapter == "ì˜ˆìƒ íš¨ìœ¨ ì‹œë®¬ë ˆì´ì…˜":
    st.header("ğŸ¯ ë‚´ ìºë¦­í„° íš¨ìœ¨ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜")

    # ì§ì—… ëª©ë¡ ë° ê¸°ì¤€ ì§ì—… ì„¤ì • (ì´ì „ ë¡œì§ ìœ ì§€)
    all_jobs = df['ì§ì—…ë¶„ë¥˜'].unique().tolist()
    try:
        modeled_jobs = [col.replace('Job_', '') for col in model.params.index if col.startswith('Job_')]
        remaining_jobs = [job for job in all_jobs if job not in modeled_jobs]
        # ëª¨ë¸ í•™ìŠµì—ì„œ ì œì™¸ëœ 'ì›ë˜' ê¸°ì¤€ ì§ì—…êµ° (ë”ë¯¸ ë³€ìˆ˜ drop_first=Trueë¡œ ì¸í•´ ì ˆí¸ì— í¡ìˆ˜ë¨)
        original_reference_job = remaining_jobs[0] if remaining_jobs else all_jobs[0]
        analysis_jobs = [original_reference_job] + modeled_jobs
    except (NameError, AttributeError):
        st.warning("ê²½ê³ : íšŒê·€ ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•„ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    except AttributeError:
        # model.paramsê°€ ì—†ëŠ” ê²½ìš° (í•™ìŠµ ì‹¤íŒ¨ ë“±)
        st.warning("ê²½ê³ : íšŒê·€ ëª¨ë¸ í•™ìŠµì´ ì‹¤íŒ¨í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # 1. --- ì…ë ¥ í•„ë“œ ì„¹ì…˜ (ì»¨í…Œì´ë„ˆ ë°–ì— ìœ„ì¹˜) ---
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ë‚˜ì˜ ìŠ¤í™ ì…ë ¥ (í†µì œ ë³€ìˆ˜)")
        # í‰ê· ì¹˜ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        default_stat = int(df['ì£¼ìŠ¤íƒ¯'].mean())
        input_main_stat = st.number_input("ì£¼ìŠ¤íƒ¯", min_value=1, value=default_stat, step=10000)
        
        default_boss = int(df['ë³´ìŠ¤_ëª¬ìŠ¤í„°_ë°ë¯¸ì§€'].mean())
        input_boss_dmg = st.number_input("ë³´ìŠ¤ ëª¬ìŠ¤í„° ë°ë¯¸ì§€ (%)", min_value=0, value=default_boss, step=10)
        
        default_crit = int(df['í¬ë¦¬í‹°ì»¬_ë°ë¯¸ì§€'].mean())
        input_crit_dmg = st.number_input("í¬ë¦¬í‹°ì»¬ ë°ë¯¸ì§€ (%)", min_value=0, value=default_crit, step=5)
        
        default_def = int(df['ë°©ì–´ìœ¨_ë¬´ì‹œ'].mean())
        input_def_ignore = st.number_input("ë°©ì–´ìœ¨ ë¬´ì‹œ (%)", min_value=0, value=default_def, step=5)
        
    with col2:
        st.subheader("ë¹„êµ ëŒ€ìƒ ì„ íƒ")

        user_reference_job = st.selectbox(
        "**ë¹„êµ ê¸°ì¤€** ì§ì—…êµ° ì„ íƒ",
        options=analysis_jobs,
        index=analysis_jobs.index(original_reference_job) if original_reference_job in analysis_jobs else 0,
        key="user_ref_job"
    )
        
    # ë¹„êµ ëŒ€ìƒ ì§ì—…êµ° ì„ íƒ
        target_job = st.selectbox(
            "**ë¹„êµ ëŒ€ìƒ** ì§ì—…êµ° ì„ íƒ",
            options=analysis_jobs,
            index=analysis_jobs.index(original_reference_job) if original_reference_job in analysis_jobs else 0,
            key="target_job"
        )
        # ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
        st.markdown("---")
        st.markdown("ëª¨ë¸ì— ì‚¬ìš©ëœ ìŠ¤ì¼€ì¼ëŸ¬ì™€ í†µì œ ë³€ìˆ˜ ìˆœì„œë¥¼ ë§ì¶°ì•¼ ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    analysis = st.button("ì˜ˆìƒ íš¨ìœ¨ ë¶„ì„í•˜ê¸°", use_container_width=True)
    
    if analysis:
        
        # [ìˆ˜ì •] ê¸°ì¤€ ì§ì—…ê³¼ ëŒ€ìƒ ì§ì—…ì´ ê°™ì€ì§€ í™•ì¸
        if user_reference_job == target_job:
            st.warning("ê²½ê³ : ë¹„êµ ê¸°ì¤€ ì§ì—…ê³¼ ë¹„êµ ëŒ€ìƒ ì§ì—…ì´ ë™ì¼í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ì—…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            st.stop()
        
        # 1. ì…ë ¥ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ êµ¬ì„± (ì›ë˜ í†µì œ ë³€ìˆ˜ ìˆœì„œëŒ€ë¡œ)
        input_data = pd.DataFrame({
            'ì£¼ìŠ¤íƒ¯': [input_main_stat], 
            'ë³´ìŠ¤_ëª¬ìŠ¤í„°_ë°ë¯¸ì§€': [input_boss_dmg],
            'í¬ë¦¬í‹°ì»¬_ë°ë¯¸ì§€': [input_crit_dmg],
            'ë°©ì–´ìœ¨_ë¬´ì‹œ': [input_def_ignore]
        })

        # 2. í†µì œ ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (ì´ë¯¸ fitëœ scaler ì‚¬ìš©)
        scaled_control = scaler.transform(input_data[X_control.columns])
        scaled_control_df = pd.DataFrame(scaled_control, columns=X_control.columns)
        
        # 3. ì˜ˆì¸¡ ë¡œì§ í•¨ìˆ˜ ì •ì˜: íŠ¹ì • ì§ì—…ì˜ ë¡œê·¸ ì „íˆ¬ë ¥ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜
        def predict_log_power(job_name, scaled_data):
            job_dummies_cols = [f'Job_{job}' for job in modeled_jobs]
            job_dummies_data = pd.DataFrame(0, index=[0], columns=job_dummies_cols)
            
            # ì˜ˆì¸¡í•˜ë ¤ëŠ” ì§ì—…ì´ original_reference_jobì´ ì•„ë‹ ê²½ìš°ì—ë§Œ í•´ë‹¹ ë”ë¯¸ ë³€ìˆ˜ë¥¼ 1ë¡œ ì„¤ì •
            if job_name != original_reference_job:
                target_col = f'Job_{job_name}'
                if target_col in job_dummies_cols:
                    job_dummies_data[target_col] = 1

            # ìµœì¢… ì˜ˆì¸¡ìš© X í–‰ë ¬ êµ¬ì„±
            X_pred_raw = pd.concat([scaled_data, job_dummies_data], axis=1)
            X_pred = sm.add_constant(X_pred_raw, has_constant='add')
            X_pred = X_pred[model.params.index] # OLS ëª¨ë¸ ì»¬ëŸ¼ ìˆœì„œ ê°•ì œ ì ìš©
            
            return model.predict(X_pred)[0]

        # 4. ì˜ˆì¸¡ê°’ ê³„ì‚°
        # ì‚¬ìš©ì ê¸°ì¤€ ì§ì—… ì˜ˆì¸¡
        predicted_log_ref = predict_log_power(user_reference_job, scaled_control_df)
        predicted_power_ref = np.expm1(predicted_log_ref)
        
        # ëª©í‘œ ì§ì—… ì˜ˆì¸¡
        predicted_log_target = predict_log_power(target_job, scaled_control_df)
        predicted_power_target = np.expm1(predicted_log_target)
        
        # 5. ì „íˆ¬ë ¥ ì°¨ì´ ê³„ì‚°
        power_diff = predicted_power_target - predicted_power_ref
        power_ratio = (predicted_power_target / predicted_power_ref) - 1
        
        # --- ê²°ê³¼ ì¶œë ¥ ---
        st.subheader(f"ğŸ“Š **{user_reference_job} vs {target_job}** ì˜ˆìƒ íš¨ìœ¨ ë¶„ì„ ê²°ê³¼")
        
        col_res1, col_res2, col_res3 = st.columns(3)
        
        with col_res1:
            st.metric(f"ê¸°ì¤€ ({user_reference_job}) ì˜ˆìƒ ì „íˆ¬ë ¥", f"{predicted_power_ref:,.0f}")
        with col_res2:
            st.metric(f"ëŒ€ìƒ ({target_job}) ì˜ˆìƒ ì „íˆ¬ë ¥", f"{predicted_power_target:,.0f}")
        with col_res3:
            st.metric(
                "ìƒëŒ€ì  íš¨ìœ¨ (ê¸°ì¤€ ëŒ€ë¹„)",
                f"{power_ratio:.1%}", 
                delta=f"{power_diff:,.0f} ì°¨ì´" 
            )
        
        # í•´ì„ ì œê³µ
        if power_ratio > 0.05:
            st.success(f"âœ… {target_job} ì§ì—…êµ°ì´ {user_reference_job} ëŒ€ë¹„ **ì•½ {power_ratio:.1%}** ë” ë†’ì€ ì „íˆ¬ë ¥ì„ ê°€ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. (ìŠ¤í™ í†µì œ)")
        elif power_ratio < -0.05:
            st.error(f"âŒ {target_job} ì§ì—…êµ°ì´ {user_reference_job} ëŒ€ë¹„ **ì•½ {-power_ratio:.1%}** ë” ë‚®ì€ ì „íˆ¬ë ¥ì„ ê°€ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. (ìŠ¤í™ í†µì œ)")
        else:
            st.info(f"ğŸ’¡ {target_job} ì§ì—…êµ°ê³¼ {user_reference_job} ì§ì—…êµ° ê°„ì˜ ì „íˆ¬ë ¥ íš¨ìœ¨ ì°¨ì´ëŠ” í¬ì§€ ì•Šì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ({power_ratio:.1%})")


elif section == "0.1. ì—°êµ¬ ë™ê¸°":
    st.header("0. ë©”ì•Œëª»ì˜ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¶„ì„ê¸°")
    st.subheader("0.1. ì—°êµ¬ ë™ê¸°")
    st.write("""
             ìµœê·¼ ê²Œì„ ì‚°ì—…ì— ê´€ì‹¬ì´ ìƒê²¼ìŠµë‹ˆë‹¤.
             \nê²Œì„ì€ ì¸ìƒì— ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ì·¨ë¯¸ë¡œ ì—¬ê²¨ì§€ê¸°ë„ í•˜ì§€ë§Œ,
             \ní•˜ë‚˜ì˜ ê²Œì„ì„ ìì„¸íˆ ëœ¯ì–´ë³´ë©´ ë†€ë¼ìš¸ ì •ë„ë¡œ ì²´ê³„ì ì¸ ì„¤ê³„ê°€ ìˆ¨ì–´ìˆì—ˆìŠµë‹ˆë‹¤.
             \nìˆ˜ë§ì€ ê²Œì„ ì¤‘ ëˆ„êµ¬ë‚˜ í•œ ë²ˆì¯¤ ë“¤ì–´ë´¤ì„ **ë©”ì´í”ŒìŠ¤í† ë¦¬**.
             \níŠ¹íˆ ë‹¤ì–‘í•œ ì§ì—…ì´ ì¡´ì¬í•˜ëŠ” ë§Œí¼ ì§ì—… ê°„ ë°¸ëŸ°ìŠ¤ê°€ ì–´ë–»ê²Œ ìœ ì§€ë˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•´ì¡ŒìŠµë‹ˆë‹¤.
             \nê²Œì„ì—ì„œ **ë°¸ëŸ°ìŠ¤**ëŠ” íŠ¹ì • ì§ì—…ì´ë‚˜ ìŠ¤í‚¬ ë“±ì´ êµ¬ì¡°ì ìœ¼ë¡œ ìœ ë¦¬í•˜ì§€ ì•Šë„ë¡ ì„¤ê³„ë˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
             \nê·¸ë ‡ë‹¤ë©´ ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—… ë°¸ëŸ°ìŠ¤ëŠ” ì‹¤ì œ ë°ì´í„°ì—ì„œë„ ê·¸ë ‡ê²Œ ë‚˜íƒ€ë‚ ê¹Œìš”?
             \nì´ëŸ¬í•œ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì „íˆ¬ë ¥ê³¼ ì¢…í•©ì ì¸ ìŠ¤íƒ¯ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬
             \nì§ì—… ê°„ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€ íšŒê·€ ë¶„ì„ì„ í†µí•´ ì‚´í´ë³´ë ¤ê³  í•©ë‹ˆë‹¤.
             
             \n\n *â€»ì£¼ì˜: ì €ëŠ” ë©”ì´í”ŒìŠ¤í† ë¦¬ë¥¼ ê¹Šê²Œ í”Œë ˆì´í•´ë³¸ ì  ì—†ëŠ” 'ë©”ì•Œëª»'ì…ë‹ˆë‹¤.*
             """)
elif section == "0.2. ë©”ì´í”ŒìŠ¤í† ë¦¬ë€?":
    st.header("0. ë©”ì•Œëª»ì˜ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¶„ì„ê¸°")
    st.subheader("0.2. ë©”ì´í”ŒìŠ¤í† ë¦¬ë€?")
    st.write("""
             ë„¥ìŠ¨ì—ì„œ ì„œë¹„ìŠ¤í•˜ëŠ” ëŒ€í‘œì ì¸ MMORPG ê²Œì„!
             \n2003ë…„ì— ì¶œì‹œëœ ì´í›„ 20ë…„ ë„˜ê²Œ ìš´ì˜ë˜ê³  ìˆëŠ” ì¥ìˆ˜ ê²Œì„ì…ë‹ˆë‹¤.
             \nê·€ì—¬ìš´ 2D ë„íŠ¸ ê·¸ë˜í”½ê³¼ ë³µì¡í•œ ì„±ì¥ êµ¬ì¡°ê°€ ë§¤ë ¥ì…ë‹ˆë‹¤.
             
             \nìºë¦­í„°ë¥¼ í‚¤ìš°ê³ , ì¥ë¹„ë¥¼ ê°•í™”í•˜ê³ , ë” ê°•í•œ ë³´ìŠ¤ë¥¼ ì¡ì•„ì•¼ í•©ë‹ˆë‹¤.
             \nì´ ê³¼ì •ì—ì„œ ìœ ì €ëŠ” í•„ìˆ˜ì ìœ¼ë¡œ ì„ íƒí•´ì•¼ í•˜ëŠ” ê²ƒì´ ìˆìŠµë‹ˆë‹¤.
             \në°”ë¡œ **ì§ì—…**ì…ë‹ˆë‹¤.
             \n
             """)
elif section == "0.3. ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…":
    st.header("0. ë©”ì•Œëª»ì˜ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¶„ì„ê¸°")
    st.subheader("0.3. ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…")
    st.write("""
             ë©”ì´í”ŒìŠ¤í† ë¦¬ì—ëŠ” ë§ì€ ì§ì—…ì´ ìˆìŠµë‹ˆë‹¤.
             \në¶„ì„ì— ì‚¬ìš©ëœ **ì „ì‚¬, ë§ˆë²•ì‚¬, ê¶ìˆ˜, ë„ì , í•´ì ** 5ê°œ ë¶„ë¥˜ì™€ ì„¸ë¶€ ì§ì—… ëª©ë¡ì…ë‹ˆë‹¤.
             """)

    all_jobs_map = {
        "ì „ì‚¬": [
            "íˆì–´ë¡œ", "íŒ”ë¼ë”˜", "ë‹¤í¬ë‚˜ì´íŠ¸", "ì†Œìš¸ë§ˆìŠ¤í„°", "ë¯¸í•˜ì¼", "ì•„ë€", 
            "ë°ëª¬ìŠ¬ë ˆì´ì–´", "ë°ëª¬ì–´ë²¤ì ¸", "ì¹´ì´ì €", "ì•„ë¸", "ë¸”ë˜ìŠ¤í„°", "ì œë¡œ"
        ],
        "ë§ˆë²•ì‚¬": [
            "ì•„í¬ë©”ì´ì§€(ë¶ˆ,ë…)", "ì•„í¬ë©”ì´ì§€(ì¬,ì½œ)", "ë¹„ìˆ", "í”Œë ˆì„ìœ„ìë“œ", 
            "ì—ë°˜", "ë£¨ë¯¸ë„ˆìŠ¤", "ë°°í‹€ë©”ì´ì§€", "ì¼ë¦¬ì›€", "ë¼ë¼", "í‚¤ë„¤ì‹œìŠ¤"
        ],
        "ê¶ìˆ˜": [
            "ë³´ìš°ë§ˆìŠ¤í„°", "ì‹ ê¶", "ìœˆë“œë¸Œë ˆì´ì»¤", "ë©”ë¥´ì„¸ë°ìŠ¤", "ì™€ì¼ë“œí—Œí„°", "ì¹´ì¸"
        ],
        "ë„ì ": [
            "ë‚˜ì´íŠ¸ë¡œë“œ", "ì„€ë„ì–´", "ë“€ì–¼ë¸”ë ˆì´ë“œ", "ë‚˜ì´íŠ¸ì›Œì»¤", "íŒ¬í…€", "ì¹´ë°ë‚˜", "ì¹¼ë¦¬"
        ],
        "í•´ì ": [
            "ë°”ì´í¼", "ìº¡í‹´", "ìŠ¤íŠ¸ë¼ì´ì»¤", "ì€ì›”", "ì—”ì ¤ë¦­ë²„ìŠ¤í„°", "ì•„í¬", "ì œë…¼", "ìºë…¼ë§ˆìŠ¤í„°"
        ]
    }

    data = []
    for group, jobs in all_jobs_map.items():
        data.append({'í° ì§ì—… ë¶„ë¥˜': group, 'ì„¸ë¶€ ì§ì—… ëª©ë¡': ', '.join(sorted(jobs))})

    full_job_df = pd.DataFrame(data)

    st.dataframe(full_job_df, use_container_width=True)


elif section == "1.1.-1.4. ë¶„ì„ ë°©ë²•":
    # 1. ë¶„ì„ ë°©ë²•
    st.header("1. ë¶„ì„ ë°©ë²•")
    st.subheader("1.1. ê°€ì„¤")
    st.write("""
             #### ê·€ë¬´ê°€ì„¤
             \në‹¤ë¥¸ ìŠ¤í™ ìš”ì¸ì„ í†µì œí•  ê²½ìš°, ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…ì€ ì „íˆ¬ë ¥ì— **í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤**.
             \n#### ëŒ€ë¦½ê°€ì„¤
             \në‹¤ë¥¸ ìŠ¤í™ ìš”ì¸ì„ í†µì œí•˜ë”ë¼ë„, ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…ì€ ì „íˆ¬ë ¥ì— **í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤**.
             \nâ–· ë³¸ ë¶„ì„ì—ì„œ ì§ì—…ì— ë”°ë¥¸ ì „íˆ¬ë ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šì„ ê²½ìš°, ì§ì—… ê°„ ë°¸ëŸ°ìŠ¤ê°€ ë¹„êµì  ì˜ ìœ ì§€ë˜ê³  ìˆë‹¤ê³  í•´ì„í•©ë‹ˆë‹¤.
             """)

    st.subheader("1.2. ë°ì´í„° ìˆ˜ì§‘")
    st.write("""
             #### ë°ì´í„° ìˆ˜ì§‘
             \në„¥ìŠ¨ open apiì—ì„œ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.
             \n#### í‘œë³¸
             \në‹¤ì„¯ ê°œì˜ ì›”ë“œ(ìŠ¤ì¹´ë‹ˆì•„, ë£¨ë‚˜, ë² ë¼, í¬ë¡œì•„, ì—˜ë¦¬ì‹œì›€)ì˜ ìƒìœ„ 2000ëª… ì¤‘ ê°ê° ë¬´ì‘ìœ„ë¡œ 60ëª…ì”© ì¶”ì¶œ
             \n#### ê³¼ì •
             \nìƒìœ„ 2000ëª… ë‹‰ë„¤ì„ ìˆ˜ì§‘ â†’ ë‹‰ë„¤ì„ì„ í†µí•´ ocid ì¶”ì¶œ â†’ ocidë¡œ ì¢…í•© ìŠ¤íƒ¯ ì¶”ì¶œ
             \nâ–· ì„œë²„ í¸í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ ì„±ê²©ì´ ë‹¤ë¥¸ ì›”ë“œë¥¼ í˜¼í•©í•˜ì—¬ í‘œë³¸ êµ¬ì„±
             \nâ–· ì¥ë¹„ ë“± ì¢…í•© ìŠ¤íƒ¯ ì´ì™¸ì˜ ì˜í–¥ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ìƒìœ„ê¶Œì—ì„œ í‘œë³¸ ì¶”ì¶œ
             \nâ–· ìˆ˜ì¹˜ê°€ 0ì´ê±°ë‚˜ ë¹„ê³µê°œì—¬ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ì œì™¸í•˜ì—¬ ì´ **273ê°œ**ì˜ í‘œë³¸ íšë“
             \nâ–· apiì˜ í•˜ë£¨ í˜¸ì¶œëŸ‰ì´ 1000ë²ˆì´ë¯€ë¡œ, ì›”ë“œë‹¹ 30ê°œë¡œ ê²°ì •
             """)
    
    all_variables = {
        "ì£¼ìŠ¤íƒ¯": "ê° ì§ì—…ì´ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ëŠ¥ë ¥ì¹˜ì˜ í•© (ì „ì‚¬ STR, ë§ˆë²•ì‚¬ INT, ê¶ìˆ˜ DEX, ë„ì  LUK)",
        "ë³´ìŠ¤ ëª¬ìŠ¤í„° ë°ë¯¸ì§€": "ë³´ìŠ¤ ëª¬ìŠ¤í„°ì—ê²Œ ì£¼ëŠ” í”¼í•´ëŸ‰ì„ ì¶”ê°€ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” ìŠ¤íƒ¯",
        "ë°©ì–´ìœ¨ ë¬´ì‹œ": "ëª¬ìŠ¤í„°ì˜ ë°©ì–´ë ¥ì„ ë¬´ì‹œí•˜ê³  ê³µê²©í•  ìˆ˜ ìˆëŠ” ë¹„ìœ¨",
        "í¬ë¦¬í‹°ì»¬ ë°ë¯¸ì§€": "ì¹˜ëª…íƒ€ ë°œìƒ ì‹œ í”¼í•´ëŸ‰ ì¦ê°€ ë¹„ìœ¨",
        "ì§ì—…êµ°": "ë©”ì´í”ŒìŠ¤í† ë¦¬ì˜ ì§ì—…ì„ 5ê°€ì§€ë¡œ ë‚˜ëˆˆ ê²ƒ (ê¶ìˆ˜, ë„ì , ë§ˆë²•ì‚¬, ì „ì‚¬, í•´ì )"
    }

    data = []
    for words, meaning in all_variables.items():
        data.append({'ë³€ìˆ˜ ëª©ë¡': words, 'ì„¤ëª…': meaning})

    variables_df = pd.DataFrame(data)
    
    st.subheader("1.3. ë³€ìˆ˜")
    st.write("""
             - ë…ë¦½ë³€ìˆ˜: ì§ì—…êµ°, ì£¼ìŠ¤íƒ¯, ë³´ìŠ¤ ëª¬ìŠ¤í„° ë°ë¯¸ì§€, í¬ë¦¬í‹°ì»¬ ë°ë¯¸ì§€, ë°©ì–´ìœ¨ ë¬´ì‹œ
             \n- ì¢…ì†ë³€ìˆ˜: ì „íˆ¬ë ¥
             \n â–· ì§ì—…êµ°ì€ ë”ë¯¸ë³€ìˆ˜ë¡œ ë³€í™˜ (í•´ë‹¹ ì§ì—…êµ°ì¼ ê²½ìš° 1, ì•„ë‹ ê²½ìš° 0)
             \n â–· ì§ì—…êµ° ì´ì™¸ì˜ ë³€ìˆ˜ëŠ” í†µì œë³€ìˆ˜ë¡œ í™œìš©
             """)
    
    st.dataframe(variables_df, use_container_width=True)

    st.subheader("1.4. ë¶„ì„ ë°©ë²•")
    st.write("""
             #### ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ë¡œ ë¶„ì„
             \n1. ê¶ìˆ˜ ì§ì—…êµ°ê³¼ íƒ€ ì§ì—…êµ°ì„ ë¹„êµ
             \n2. ì„ í˜• íšŒê·€ë¡œ ë¶„ì„í•˜ê¸° ìœ„í•´ ë¡œê·¸í”ŒëŸ¬ìŠ¤ì› ë³€í™˜ [np.log1p(df['ì „íˆ¬ë ¥'])]
             \n3. StandardScalerë¥¼ í†µí•´ ë³€ìˆ˜ê°„ ìŠ¤ì¼€ì¼ ì¡°ì • (í‘œì¤€í™”)
             \n4. ë³€ìˆ˜ê°„ ë‹¤ì¤‘ê³µì„ ì„± íŒŒì•… [variance_inflation_factor]
             \n#### ê²°ê³¼ ë¶„ì„ ë°©ë²•
             \n1. p-valueê°€ 0.05 ì´í•˜ì¸ ê²½ìš° ìœ ì˜í•˜ë‹¤ê³  íŒì •
             \n2. ì”ì°¨ ì‚°ì ë„: ëª¨ë¸ì´ ë°ì´í„°ì˜ ì„ í˜•ì„± ê°€ì •ì„ ì˜ ì¶©ì¡±í•˜ëŠ”ì§€ ì‹œì‘ì ìœ¼ë¡œ ê²€í† 
             \n3. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ: ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íŒŒì•…
             """)

    st.markdown("---")

elif section == "2.1. ì§ì—… ë¶„ë¥˜ ìƒì„¸ ì •ë³´":
    st.header("2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ê²°ê³¼")
    st.markdown("**ì¢…ì† ë³€ìˆ˜:** $\ln(\text{ì „íˆ¬ë ¥}+1)$ (ë¡œê·¸ ë³€í™˜)")
    
    # ì‹¤ì œ ì œì™¸ëœ ê¸°ì¤€ ê·¸ë£¹ì„ ì°¾ì•„ í‘œì‹œí•©ë‹ˆë‹¤.
    all_groups = sorted(df['ì§ì—…ë¶„ë¥˜'].unique()) # ëª¨ë“  ì§ì—… ë¶„ë¥˜ë¥¼ ì •ë ¬
    if all_groups:
        reference_group = all_groups[0] # ì •ë ¬ ìˆœì„œìƒ ì²« ë²ˆì§¸ ê·¸ë£¹ì´ drop_first=Trueì— ì˜í•´ ì œì™¸ë¨
        st.markdown(f"**ê¸°ì¤€ ì§ì—… ë¶„ë¥˜:** **{reference_group}** (ë”ë¯¸ ë³€ìˆ˜ì—ì„œ ì œì™¸ëœ ê·¸ë£¹)")
    else:
        st.markdown("**ê¸°ì¤€ ì§ì—… ë¶„ë¥˜:** ë°ì´í„°ì— ì§ì—… ë¶„ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")


    # --- 3. Streamlit ëŒ€ì‹œë³´ë“œ êµ¬ì„± --- (ì´ ì„¹ì…˜ ì‹œì‘ ì „ì— ì¶”ê°€)

    # 0. ì§ì—… ë¶„ë¥˜ ë§¤í•‘ í…Œì´ë¸” ìƒì„±
    st.subheader("2.1. ì§ì—… ë¶„ë¥˜ ìƒì„¸ ì •ë³´")
    st.markdown("ë¶„ì„ ëŒ€ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **í° ì§ì—… ë¶„ë¥˜**ì™€ ì´ì— ì†í•˜ëŠ” **ì„¸ë¶€ ì§ì—…** ëª©ë¡ì…ë‹ˆë‹¤.")

    # 1. 'ì§ì—…ë¶„ë¥˜'ì™€ 'ì§ì—…' ì»¬ëŸ¼ë§Œì„ ì„ íƒí•˜ê³  ì¤‘ë³µ ì œê±°
    job_mapping_df = df[['ì§ì—…ë¶„ë¥˜', 'ì§ì—…']].drop_duplicates().reset_index(drop=True)

    # 2. 'ì§ì—…ë¶„ë¥˜'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì„¸ë¶€ ì§ì—…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ìŒ
    # íŒŒì´ì¬ì˜ groupbyì™€ join í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ë¶€ ì§ì—…ì„ ì‰¼í‘œ(,)ë¡œ ì—°ê²°
    grouped_jobs = job_mapping_df.groupby('ì§ì—…ë¶„ë¥˜')['ì§ì—…'].apply(lambda x: ', '.join(sorted(x))).reset_index()

    # 3. Streamlitì— í‘œë¡œ ì¶œë ¥
    grouped_jobs.columns = ['í° ì§ì—… ë¶„ë¥˜', 'ì„¸ë¶€ ì§ì—… ëª©ë¡']
    st.dataframe(grouped_jobs, use_container_width=True)

elif section == "2.2. íšŒê·€ ë¶„ì„ ê²°ê³¼":
    st.header("2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ê²°ê³¼")
    st.markdown("**ì¢…ì† ë³€ìˆ˜:** $\ln(\text{ì „íˆ¬ë ¥}+1)$ (ë¡œê·¸ ë³€í™˜)")
    st.subheader("2.2. íšŒê·€ ë¶„ì„ ê²°ê³¼")

    st.code(model.summary().as_text(), language='text')

    st.write("""#### ê²°ê³¼ í•´ì„
             \nR-squared: 0.72""")


    st.write("#### ì§ì—… ë¶„ë¥˜ë³„ ì „íˆ¬ë ¥ ì˜í–¥ (íšŒê·€ê³„ìˆ˜)")
    st.markdown("ê³„ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê¸°ì¤€ ê·¸ë£¹(ê¶ìˆ˜) ëŒ€ë¹„ íš¨ìœ¨ì´ ì¢‹ìŠµë‹ˆë‹¤.")
    
    job_coeffs = model.params[model.params.index.str.startswith('Job')]
    job_pvalues = model.pvalues[model.pvalues.index.str.startswith('Job')]
    
    coeff_df = pd.DataFrame({
        'íšŒê·€ê³„ìˆ˜': job_coeffs,
        'P-value': job_pvalues
    })
    
    coeff_df['ìœ ì˜ì„±'] = np.where(coeff_df['P-value'] < 0.05, 'ìœ ì˜í•¨ (p < 0.05)', 'ìœ ì˜í•˜ì§€ ì•ŠìŒ')
    coeff_df = coeff_df.sort_values(by='íšŒê·€ê³„ìˆ˜', ascending=False)
    
    st.dataframe(coeff_df)
    
    
    # Streamlit ë„¤ì´í‹°ë¸Œ ì°¨íŠ¸ë¥¼ ìœ„í•´ Indexë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    coeff_df_chart = coeff_df.reset_index()
    coeff_df_chart.columns = ['ì§ì—… ë¶„ë¥˜', 'íšŒê·€ ê³„ìˆ˜', 'P-value', 'ìœ ì˜ì„±']

    # ë„¤ì´í‹°ë¸Œ ì°¨íŠ¸ ì¶œë ¥ (ìƒ‰ìƒ êµ¬ë¶„ì´ ì–´ë ¤ìš°ë¯€ë¡œ ë³„ë„ ë§ˆí¬ë‹¤ìš´ ì„¤ëª… í•„ìš”)
    st.bar_chart(
        coeff_df_chart, 
        x='ì§ì—… ë¶„ë¥˜', 
        y='íšŒê·€ ê³„ìˆ˜', 
        color='íšŒê·€ ê³„ìˆ˜' # ê°’ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìƒ‰ìƒì„ ë‹¤ë¥´ê²Œ í‘œì‹œ
    )

elif section == "2.3. ê·¸ë˜í”„":
    st.header("2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ê²°ê³¼")
    st.subheader("2.3. ê·¸ë˜í”„")
        
    # 1. ì”ì°¨ ì‚°ì ë„
    st.write("#### ëª¨ë¸ ì§„ë‹¨: ì”ì°¨ ì‚°ì ë„")
    st.write("""ì˜ˆì¸¡ê°’($\hat{Y}$)ì— ë”°ë¥¸ ì”ì°¨($Y - \hat{Y}$)ì˜ ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
             \nì”ì°¨ë“¤ì´ 0ì„ ì¤‘ì‹¬ìœ¼ë¡œ **ë¬´ì‘ìœ„ë¡œ** ë¶„í¬í•´ì•¼ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ê°€ì •ì´ ì¶©ì¡±ë©ë‹ˆë‹¤.
             """)

    # ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ê³„ì‚°
    predicted_Y = model.fittedvalues
    # ëª¨ë¸ì˜ ì”ì°¨(Residuals) ê³„ì‚°
    residuals = model.resid
    
    # ë„¤ì´í‹°ë¸Œ ì°¨íŠ¸ë¥¼ ìœ„í•´ ë‘ ë°°ì—´ì„ DataFrameìœ¼ë¡œ ë³‘í•©
    residual_chart_df = pd.DataFrame({
        'ì˜ˆì¸¡ëœ ë¡œê·¸ ì „íˆ¬ë ¥': predicted_Y,
        'ì”ì°¨': residuals
    })

    st.scatter_chart(
        residual_chart_df,
        x='ì˜ˆì¸¡ëœ ë¡œê·¸ ì „íˆ¬ë ¥',
        y='ì”ì°¨',
    )

    st.write("""
             ì”ì°¨ê°€ ì˜ˆì¸¡ê°’ ì „ë°˜ì— ê±¸ì³ **ë¬´ì‘ìœ„ì ìœ¼ë¡œ ë¶„í¬**í•˜ê³  ìˆìŠµë‹ˆë‹¤.
             \nâ–· ì„ í˜• íšŒê·€ëª¨í˜•ì˜ ê¸°ë³¸ ê°€ì •ì´ í¬ê²Œ ìœ„ë°°ë˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.
             """)


    # 2. ë‹¤ì¤‘ê³µì„ ì„± ì§„ë‹¨ (VIF)
    st.write("#### ë‹¤ì¤‘ê³µì„ ì„± ì§„ë‹¨")
    st.write("ì£¼ìš” í†µì œ ë³€ìˆ˜(ìŠ¤í™) ê°„ì˜ ë‹¤ì¤‘ê³µì„ ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ì¤‘ê³µì„ ì„±ì´ 10ì„ ì´ˆê³¼í•˜ë©´ ë³€ìˆ˜ ê°„ ìƒê´€ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.")
    
    try:
        vif_data = pd.DataFrame()
        vif_data["feature"] = X_control.columns
        vif_data["VIF"] = [variance_inflation_factor(X_control_scaled.values, i) for i in range(len(X_control_scaled.columns))]
        
        st.dataframe(vif_data.sort_values(by="VIF", ascending=False))
    except Exception as e:
        st.warning(f"VIF ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. (ì£¼ë¡œ ìƒ˜í”Œ ë¶€ì¡± ë˜ëŠ” ëª¨ë“  ê°’ì´ 0ì¸ ê²½ìš° ë°œìƒ)")

    # 3. í†µì œ ë³€ìˆ˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    st.write("#### í†µì œ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„: íˆíŠ¸ë§µ")
    
    fig_corr, ax_corr = plt.subplots(figsize=(8, 6))
    sns.heatmap(X_control.corr(), annot=True, cmap='coolwarm', fmt=".2f", ax=ax_corr)
    ax_corr.set_title("ìŠ¤í™ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„")
    st.pyplot(fig_corr)

